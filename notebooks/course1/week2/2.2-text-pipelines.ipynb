{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.2: Text Pipelines\n",
    "\n",
    "**Objective**: Run inference using transformers pipelines for text tasks\n",
    "\n",
    "**Duration**: 30 minutes\n",
    "\n",
    "## Learning Outcomes\n",
    "- Use pipeline() for sentiment analysis\n",
    "- Run text generation pipelines\n",
    "- Perform summarization and translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../../src\")\n",
    "from hf_ecosystem import __version__\n",
    "print(f\"hf-ecosystem version: {__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from hf_ecosystem.inference import create_pipeline, get_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment pipeline\n",
    "sentiment = create_pipeline(\"sentiment-analysis\", device=\"cpu\")\n",
    "\n",
    "# Analyze text\n",
    "results = sentiment([\"I love this product!\", \"This is terrible.\"])\n",
    "for r in results:\n",
    "    print(f\"{r['label']}: {r['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\", device=\"cpu\")\n",
    "output = generator(\"The future of AI is\", max_length=30, num_return_sequences=1)\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Manual summarization (pipeline task removed in transformers 5.0)\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nmodel_id = \"sshleifer/distilbart-cnn-6-6\"\nsummarizer_model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\nsummarizer_tokenizer = AutoTokenizer.from_pretrained(model_id)\n\ntext = \"\"\"Machine learning is a subset of artificial intelligence that enables \nsystems to learn and improve from experience without being explicitly programmed.\nIt focuses on developing algorithms that can access data and use it to learn for themselves.\"\"\"\n\ninputs = summarizer_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\noutputs = summarizer_model.generate(**inputs, max_new_tokens=50, min_new_tokens=10)\nsummary = summarizer_tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(f\"Summary: {summary}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_lab():\n",
    "    assert len(results) == 2\n",
    "    assert results[0][\"label\"] == \"POSITIVE\"\n",
    "    print(\"âœ… Lab completed successfully!\")\n",
    "\n",
    "verify_lab()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
