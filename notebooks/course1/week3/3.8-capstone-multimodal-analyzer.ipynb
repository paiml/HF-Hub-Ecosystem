{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.8: Capstone - Multi-Modal Content Analyzer\n",
    "\n",
    "**Objective**: Build a unified system that analyzes text and images using Hugging Face Hub models\n",
    "\n",
    "**Duration**: 55 minutes\n",
    "\n",
    "## Learning Outcomes\n",
    "- Search the Hub programmatically for models\n",
    "- Load and explore datasets\n",
    "- Build inference pipelines for multiple modalities\n",
    "- Create a unified analysis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../../src\")\n",
    "from hf_ecosystem import __version__\n",
    "print(f\"hf-ecosystem version: {__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from hf_ecosystem.hub import search_models\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Search the Hub Programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for top models by task\n",
    "tasks = [\"text-classification\", \"image-classification\"]\n",
    "\n",
    "for task in tasks:\n",
    "    models = search_models(task=task, limit=3)\n",
    "    print(f\"\\n{task}:\")\n",
    "    for m in models:\n",
    "        print(f\"  {m.id} ({m.downloads:,} downloads)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed model info\n",
    "api = HfApi()\n",
    "model_info = api.model_info(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "print(f\"Model: {model_info.id}\")\n",
    "print(f\"Downloads: {model_info.downloads:,}\")\n",
    "print(f\"License: {model_info.card_data.license if model_info.card_data else 'N/A'}\")\n",
    "print(f\"Tags: {model_info.tags[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Load Sample Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text dataset (movie reviews)\n",
    "text_data = load_dataset(\"rotten_tomatoes\", split=\"test[:5]\")\n",
    "print(\"Text samples:\")\n",
    "for i, example in enumerate(text_data):\n",
    "    print(f\"  {i+1}. {example['text'][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image dataset\n",
    "image_data = load_dataset(\"beans\", split=\"test[:3]\")\n",
    "print(f\"Image dataset columns: {image_data.column_names}\")\n",
    "print(f\"Labels: {image_data.features['labels'].names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Build Inference Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text classification pipeline\n",
    "text_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    device=\"cpu\"\n",
    ")\n",
    "print(f\"Text classifier loaded: {text_classifier.model.config.model_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image classification pipeline\n",
    "image_classifier = pipeline(\n",
    "    \"image-classification\",\n",
    "    model=\"google/vit-base-patch16-224\",\n",
    "    device=\"cpu\"\n",
    ")\n",
    "print(f\"Image classifier loaded: {image_classifier.model.config.model_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze text samples\n",
    "print(\"Text Sentiment Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "for example in text_data:\n",
    "    result = text_classifier(example[\"text\"])[0]\n",
    "    print(f\"Text: {example['text'][:50]}...\")\n",
    "    print(f\"Result: {result['label']} ({result['score']:.2%})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze images from dataset\n",
    "print(\"Image Classification:\")\n",
    "print(\"-\" * 50)\n",
    "for i, example in enumerate(image_data):\n",
    "    result = image_classifier(example[\"image\"])[0]\n",
    "    print(f\"Image {i+1}: {result['label']} ({result['score']:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze a web image\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    "response = requests.get(url)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Classify\n",
    "classification = image_classifier(image)[:3]\n",
    "print(\"Classification:\")\n",
    "for r in classification:\n",
    "    print(f\"  {r['label']}: {r['score']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Unified Multi-Modal Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_content(text=None, image=None):\n",
    "    \"\"\"\n",
    "    Multi-modal content analyzer.\n",
    "    \n",
    "    Args:\n",
    "        text: String to analyze for sentiment\n",
    "        image: PIL Image or URL to classify\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with analysis results\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    if text:\n",
    "        sentiment = text_classifier(text)[0]\n",
    "        results[\"text\"] = {\n",
    "            \"input\": text[:100],\n",
    "            \"sentiment\": sentiment[\"label\"],\n",
    "            \"confidence\": sentiment[\"score\"]\n",
    "        }\n",
    "    \n",
    "    if image:\n",
    "        # Handle URL input\n",
    "        if isinstance(image, str):\n",
    "            response = requests.get(image)\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "        \n",
    "        classification = image_classifier(image)[0]\n",
    "        results[\"image\"] = {\n",
    "            \"category\": classification[\"label\"],\n",
    "            \"confidence\": classification[\"score\"]\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Text only\n",
    "result = analyze_content(text=\"This product exceeded all my expectations!\")\n",
    "print(\"Text Analysis:\")\n",
    "print(f\"  Sentiment: {result['text']['sentiment']}\")\n",
    "print(f\"  Confidence: {result['text']['confidence']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Multi-modal (text + image)\n",
    "result = analyze_content(\n",
    "    text=\"What a cute cat!\",\n",
    "    image=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "print(\"Multi-Modal Analysis:\")\n",
    "print(f\"  Text sentiment: {result['text']['sentiment']} ({result['text']['confidence']:.2%})\")\n",
    "print(f\"  Image category: {result['image']['category']} ({result['image']['confidence']:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_lab():\n",
    "    \"\"\"Verify lab completion.\"\"\"\n",
    "    assert text_classifier is not None, \"Text classifier not loaded\"\n",
    "    assert image_classifier is not None, \"Image classifier not loaded\"\n",
    "    \n",
    "    test_result = analyze_content(text=\"test\")\n",
    "    assert \"text\" in test_result, \"Text analysis failed\"\n",
    "    assert \"sentiment\" in test_result[\"text\"], \"Sentiment missing\"\n",
    "    \n",
    "    print(\"All verifications passed!\")\n",
    "\n",
    "verify_lab()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
