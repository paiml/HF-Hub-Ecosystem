{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1.2: Loading Diverse Datasets\n",
    "\n",
    "**Objective**: Load datasets from Hub, local files, and various formats\n",
    "\n",
    "**Duration**: 25 minutes\n",
    "\n",
    "## Learning Outcomes\n",
    "- Load datasets from Hugging Face Hub\n",
    "- Load from CSV, JSON, and Parquet\n",
    "- Understand Dataset vs DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../../src\")\n",
    "from hf_ecosystem import __version__\n",
    "print(f\"hf-ecosystem version: {__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading from Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset (returns DatasetDict)\n",
    "imdb = load_dataset(\"imdb\")\n",
    "print(f\"Type: {type(imdb)}\")\n",
    "print(f\"Splits: {list(imdb.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load specific split\n",
    "train = load_dataset(\"imdb\", split=\"train[:100]\")\n",
    "print(f\"Type: {type(train)}\")\n",
    "print(f\"Size: {len(train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Features: {train.features}\")\n",
    "print(f\"\\nSample: {train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating from Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset from dictionary\n",
    "custom_data = {\n",
    "    \"text\": [\"Hello world\", \"Goodbye world\"],\n",
    "    \"label\": [1, 0]\n",
    "}\n",
    "custom_ds = Dataset.from_dict(custom_data)\n",
    "print(f\"Custom dataset: {custom_ds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_lab():\n",
    "    assert isinstance(imdb, DatasetDict)\n",
    "    assert isinstance(train, Dataset)\n",
    "    assert len(custom_ds) == 2\n",
    "    print(\"âœ… Lab completed successfully!\")\n",
    "\n",
    "verify_lab()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
