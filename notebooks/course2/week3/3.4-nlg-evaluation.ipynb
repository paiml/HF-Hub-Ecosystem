{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.4: NLG Evaluation\n",
    "\n",
    "**Objective**: Evaluate summarization with ROUGE\n",
    "\n",
    "**Duration**: 25 minutes\n",
    "\n",
    "## Learning Outcomes\n",
    "- Compute ROUGE scores\n",
    "- Understand ROUGE-1, ROUGE-2, ROUGE-L\n",
    "- Evaluate summarization quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../../src\")\n",
    "from hf_ecosystem import __version__\n",
    "print(f\"hf-ecosystem version: {__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ROUGE Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "predictions = [\"The cat sat on the mat.\"]\n",
    "references = [\"The cat is sitting on the mat.\"]\n",
    "\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(f\"ROUGE-1: {results['rouge1']:.3f}\")\n",
    "print(f\"ROUGE-2: {results['rouge2']:.3f}\")\n",
    "print(f\"ROUGE-L: {results['rougeL']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding ROUGE\n",
    "\n",
    "- **ROUGE-1**: Unigram overlap\n",
    "- **ROUGE-2**: Bigram overlap\n",
    "- **ROUGE-L**: Longest common subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different summaries\n",
    "summaries = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"A feline rested on the floor.\",\n",
    "    \"Dogs are great pets.\",\n",
    "]\n",
    "\n",
    "for summary in summaries:\n",
    "    result = rouge.compute(predictions=[summary], references=references)\n",
    "    print(f\"{summary[:30]}... ROUGE-L: {result['rougeL']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_lab():\n",
    "    assert \"rouge1\" in results\n",
    "    assert results[\"rouge1\"] > 0\n",
    "    print(\"âœ… Lab completed successfully!\")\n",
    "\n",
    "verify_lab()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
